import asyncio
import sys
import os
import csv
from datetime import datetime
import requests
import urllib.parse
import httpx
from bs4 import BeautifulSoup
import random

# Add the app directory to the Python path
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

from app.services.web_agent_workflow_service import web_agent_workflow

# test_web_agent.py ì „ìš© WebSearchTool í´ë˜ìŠ¤ (SearchAPI ì‚¬ìš©)
class WebSearchTool:
    """í…ŒìŠ¤íŠ¸ìš© WebSearchTool - SearchAPI ì‚¬ìš©"""

    # User-Agent í’€
    USER_AGENTS = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0",
    ]

    def __init__(self, query: str, num_results: int = 5):
        self.query = query
        self.num_results = num_results
        self.api_key = 'q4wGQfPGh3kPd1AqsHBp7EKn'

    async def _fetch_search_results(self) -> list:
        """SearchAPIë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        encoded_query = urllib.parse.quote(self.query)
        url = f"https://www.searchapi.io/api/v1/search?engine=google&gl=kr&hl=ko&q={encoded_query}&api_key={self.api_key}"

        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            data = response.json()
            return data.get("organic_results", [])
        except Exception as e:
            print(f"[ì˜¤ë¥˜] SearchAPI ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

    async def _scrape_page(self, url: str) -> str:
        """ì£¼ì–´ì§„ URLì˜ ì›¹ í˜ì´ì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ì—¬ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            user_agent = random.choice(self.USER_AGENTS)
            headers = {
                "User-Agent": user_agent,
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                "Accept-Encoding": "gzip, deflate, br",
                "Connection": "keep-alive",
                "Upgrade-Insecure-Requests": "1",
            }

            async with httpx.AsyncClient(
                follow_redirects=True,
                verify=False,
                timeout=15.0
            ) as client:
                response = await client.get(url, headers=headers)
                response.raise_for_status()

            soup = BeautifulSoup(response.text, "html.parser")
            for script_or_style in soup(["script", "style"]):
                script_or_style.decompose()

            selectors = ["#article_body", "#dic_area", "#newsct_article", ".article_view", "#article-view-content-div", "#contents", ".content"]
            content_html = None
            for selector in selectors:
                content_html = soup.select_one(selector)
                if content_html:
                    break

            text_content = content_html.get_text() if content_html else soup.get_text()

            lines = (line.strip() for line in text_content.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            content = "\n".join(chunk for chunk in chunks if chunk)[:4000]
            return content
        except Exception as e:
            print(f"[ì˜¤ë¥˜] ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {url}, ì˜¤ë¥˜: {e}")
            return ""

    async def search_and_scrape(self) -> list[dict]:
        """SearchAPIë¡œ ê²€ìƒ‰ í›„ ê° ê²°ê³¼ í˜ì´ì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ì—¬ ë¬¸ì„œ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        search_results = await self._fetch_search_results()

        if not search_results:
            return []

        # í•„ìš”í•œ ê°œìˆ˜ë§Œí¼ ê²°ê³¼ ì œí•œ
        search_results = search_results[:self.num_results + 5]  # ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ëŒ€ë¹„ ì—¬ìœ ë¶„

        tasks = [self._scrape_page(r.get("link", "")) for r in search_results if r.get("link")]
        scraped_contents = await asyncio.gather(*tasks)

        documents = []
        for r, c in zip(search_results, scraped_contents):
            if c and r.get("link"):
                documents.append({
                    "title": r.get("title", ""),
                    "link": r.get("link"),
                    "snippet": r.get("snippet", ""),
                    "publish_date": r.get("date", ""),
                    "content": c,
                })
            if len(documents) == self.num_results:
                break

        return documents

# ì •ëŸ‰ í‰ê°€ìš© 20ê°œ ì§ˆë¬¸
EVALUATION_QUESTIONS = [
    "í•œêµ­ì€í–‰ì˜ ê¸°ì¤€ê¸ˆë¦¬ ë™ê²°ì´ ê°€ê³„ëŒ€ì¶œ ì¦ê°€ìœ¨ê³¼ DSR ê·œì œ íš¨ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì¤˜.",
    "ì¤‘êµ­ì˜ ë°˜ë„ì²´ êµ´ê¸° ì •ì±…ì´ í•œêµ­ ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ì—…ì²´ë“¤(SKí•˜ì´ë‹‰ìŠ¤, ì‚¼ì„±ì „ì)ì—ê²Œ ë¯¸ì¹˜ëŠ” ì¥ê¸°ì  ì˜í–¥ì„ í‰ê°€í•´ì¤˜.",
    "K-ë·°í‹° ì—…ê³„ì˜ ì¤‘êµ­ ì˜ì¡´ë„ ê°ì†Œ ì „ëµê³¼ ì‹ ë‚¨ë°© ì‹œì¥ ì§„ì¶œ í˜„í™©ì„ ë¶„ì„í•´ì¤˜.",
    "ê°€ê³„ëŒ€ì¶œ ì´ëŸ‰ê·œì œ ê°•í™”ê°€ ì§€ì—­ë³„ ë¶€ë™ì‚° ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì°¨ë³„ì  ì˜í–¥ì„ ë¶„ì„í•´ì¤˜.",
    "ì¹´ì¹´ì˜¤í˜ì´, í† ìŠ¤ ë“± í•€í…Œí¬ ì—…ì²´ë“¤ì˜ ìˆ˜ìµëª¨ë¸ ë‹¤ê°í™” ì „ëµê³¼ ê¸°ì¡´ ì€í–‰ê¶Œê³¼ì˜ ê²½ìŸêµ¬ë„ë¥¼ ë¶„ì„í•´ì¤˜.",
    "ì¸í”Œë ˆì´ì…˜ í—¤ì§€ë¥¼ ìœ„í•´ì„œëŠ” ì–´ë–¤ ìì‚°ì— íˆ¬ìí•´ì•¼ í•˜ë‚˜?",
    "HBM ë©”ëª¨ë¦¬ ì‹œì¥ì—ì„œ SKí•˜ì´ë‹‰ìŠ¤ê°€ ì‚¼ì„±ì „ìë¥¼ ì•ì„œê³  ìˆëŠ” ì´ìœ ëŠ”?",
    "êµ­ë‚´ ì¹´ë“œì‚¬ë“¤ ì¤‘ì—ì„œ ì‹¤ì ì´ ê°€ì¥ ì¢‹ì€ ê³³ì€ ì–´ë””ê³ , ê·¸ ì´ìœ ëŠ”?",
    "ê¸°ì—…ë¶„ì„ ë³´ê³ ì„œ ì‘ì„± ì‹œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë´ì•¼ í•  ì§€í‘œ 3ê°€ì§€ëŠ”?",
    "ì¬ê±´ì¶• vs ì¬ê°œë°œ, ì–´ëŠ ìª½ì´ ìˆ˜ìµì„±ì´ ë” ë†’ì„ê¹Œ?",
    "ë§Œì•½ ëŒ€ë§Œì´ ì¹¨ê³µë‹¹í•  ê²½ìš°, ê¸€ë¡œë²Œ ë°˜ë„ì²´ ê³µê¸‰ë§ì€ ì–´ë–»ê²Œ ë ê¹Œ?",
    "ì™œ ì¼ë³¸ì€ 30ë…„ ë„˜ê²Œ ë””í”Œë ˆì´ì…˜ì—ì„œ ë²—ì–´ë‚˜ì§€ ëª»í•˜ê³  ìˆì„ê¹Œ?",
    "ê³µë§¤ë„ ê¸ˆì§€ê°€ ì£¼ê°€ì— ë¯¸ì¹˜ëŠ” ì‹¤ì œ íš¨ê³¼ëŠ” ì–´ë–¤ ì›ë¦¬ë¡œ ì‘ë™í•˜ë‚˜?",
    "ë¯¸êµ­ê³¼ ì¤‘êµ­ì˜ ê²½ìŸìœ¼ë¡œ ë°˜ë„ì²´ ê³µê¸‰ë§ì´ ë°”ë€Œê³  ìˆëŠ”ë°, ìš°ë¦¬ë‚˜ë¼ì˜ ì‘ì€ ë°˜ë„ì²´ ì¥ë¹„ë‚˜ ì†Œì¬ íšŒì‚¬ë“¤ì—ê²ŒëŠ” ì˜¤íˆë ¤ ê¸°íšŒê°€ ë ê¹Œ?",
    "ìš”ì¦˜ ê¸°ì—…ë“¤ì´ ë°°ë‹¹ê¸ˆì„ ëŠ˜ë¦¬ê³  ìˆëŠ”ë°, ì´ëŸ° ì›€ì§ì„ì´ ê³„ì†ë˜ë©´ ìš°ë¦¬ë‚˜ë¼ ì£¼ì‹ì´ ì €í‰ê°€ë°›ëŠ” ë¬¸ì œê°€ í•´ê²°ë ê¹Œ?",
    "í•œêµ­ì˜ ì¸êµ¬ ê°ì†Œì™€ ê³ ë ¹í™”ê°€ ì‹¬ê°í•´ì§€ê³  ìˆëŠ”ë°, ì´ê²Œ ì¥ê¸°ì ìœ¼ë¡œ êµ­ë¯¼ì—°ê¸ˆ ê³ ê°ˆì´ë‚˜ ë‚´ìˆ˜ ì‹œì¥ ì¹¨ì²´ë¡œ ì´ì–´ì§ˆê¹Œ?",
    "ì¸ê³µì§€ëŠ¥(AI) ê¸°ìˆ  í™•ì‚°ìœ¼ë¡œ ë°ì´í„°ì„¼í„° ì „ë ¥ ì†Œë¹„ëŸ‰ì´ ê¸‰ì¦í•˜ëŠ”ë°, ì´ê²Œ í•œêµ­ì „ë ¥ ê°™ì€ ì „ë ¥ íšŒì‚¬ë‚˜ ì›ìë ¥ ë°œì „ì— ìƒˆë¡œìš´ ê¸°íšŒê°€ ë ê¹Œ?",
    "ì¤‘êµ­ì´ ì „ê¸°ì°¨ ë°°í„°ë¦¬ì˜ í•µì‹¬ ì›ë£Œì¸ í¬í† ë¥˜ ìˆ˜ì¶œì„ í†µì œí•˜ë©´, í˜„ëŒ€ì°¨ë‚˜ ê¸°ì•„ëŠ” í° íƒ€ê²©ì„ ì…ê²Œ ë ê¹Œ?",
    "í˜„ì¬ í•œêµ­ ë¶€ë™ì‚° ì‹œì¥ì—ì„œ ê¸ˆë¦¬ ì¸ìƒì´ ì•„íŒŒíŠ¸ ê°€ê²©ê³¼ ì „ì„¸ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•´ì¤˜.",
    "ì‚¼ì„±ì „ìì˜ HBM ë©”ëª¨ë¦¬ ì‚¬ì—…ì´ AI ë°˜ë„ì²´ ì‹œì¥ì—ì„œ ì°¨ì§€í•˜ëŠ” ìœ„ì¹˜ì™€ ê²½ìŸì‚¬ ëŒ€ë¹„ ê¸°ìˆ ì  ìš°ìœ„ëŠ”?"
]

def select_llm_model():
    """LLM ëª¨ë¸ì„ ì„ íƒí•˜ëŠ” í•¨ìˆ˜"""
    print("=== LLM ëª¨ë¸ ì„ íƒ ===")
    print("1. Midm (ê¸°ë³¸ê°’)")
    print("2. SK")
    print("3. LG")
    print()

    while True:
        try:
            choice = input("ì‚¬ìš©í•  LLM ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš” (1-3): ").strip()

            if choice == "1" or choice == "":
                return "Midm"
            elif choice == "2":
                return "SK"
            elif choice == "3":
                return "LG"
            else:
                print("ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1-3)")
        except KeyboardInterrupt:
            print("\ní”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            exit()


def select_mode():
    """ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ëŠ” í•¨ìˆ˜"""
    print("\n=== ëª¨ë“œ ì„ íƒ ===")
    print("1. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ëŒ€í™”í˜•)")
    print("2. ì •ëŸ‰ í‰ê°€ ì‹¤ì‹œ")
    print()

    while True:
        try:
            choice = input("ì‹¤í–‰ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (1-2): ").strip()

            if choice == "1":
                return "search_test"
            elif choice == "2":
                return "quantitative_evaluation"
            else:
                print("ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1-2)")
        except KeyboardInterrupt:
            print("\ní”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            exit()



async def quantitative_evaluation(selected_llm):
    """ì •ëŸ‰ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ - 5ê°œì”© ë°°ì¹˜ ì²˜ë¦¬ë¡œ rate limiting ë°©ì§€"""
    print(f"\n=== ì •ëŸ‰ í‰ê°€ ì‹¤ì‹œ ({selected_llm} ëª¨ë¸) ===")
    print(f"ì´ {len(EVALUATION_QUESTIONS)}ê°œì˜ ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    print("Rate limiting ë°©ì§€ë¥¼ ìœ„í•´ 5ê°œì”© ë°°ì¹˜ ì²˜ë¦¬í•˜ë©°, ë°°ì¹˜ ê°„ 30ì´ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
    print("=" * 60)

    # ì›¹ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    try:
        web_agent = web_agent_workflow(llm_type=selected_llm, web_search_tool_class=WebSearchTool)
        print("âœ… ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        print(f"âŒ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    results = []
    batch_size = 10  # 5ê°œì—ì„œ 10ê°œë¡œ ì¦ê°€ (ì¬ì‹œë„ ë¡œì§ ë•ë¶„ì— ë” ê³µê²©ì ìœ¼ë¡œ ê°€ëŠ¥)
    total_questions = len(EVALUATION_QUESTIONS)

    # ì§ˆë¬¸ë“¤ì„ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
    for batch_start in range(0, total_questions, batch_size):
        batch_end = min(batch_start + batch_size, total_questions)
        batch_questions = EVALUATION_QUESTIONS[batch_start:batch_end]
        batch_num = (batch_start // batch_size) + 1
        total_batches = (total_questions + batch_size - 1) // batch_size

        print(f"\nğŸ”„ ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘ (ì§ˆë¬¸ {batch_start + 1}-{batch_end}ê°œ)")

        # í˜„ì¬ ë°°ì¹˜ì˜ ì§ˆë¬¸ë“¤ ì²˜ë¦¬
        for i, question in enumerate(batch_questions):
            idx = batch_start + i + 1
            print(f"\n[{idx}/{total_questions}] ì²˜ë¦¬ ì¤‘: {question[:50]}...")

            try:
                # 1. query_rewriter ì‹¤í–‰
                from app.schemas.langraph_states.state_models import web_agent_state

                state = web_agent_state(
                    user_question=question,
                    generated_queries=[],
                    collected_documents=[],
                    filtered_documents=[],
                    similarity_score=0.0,
                    final_answer="",
                    answer_type="",
                    search_results=[]
                )

                # ë‹¨ê³„ë³„ ì‹¤í–‰
                state_after_rewrite = await web_agent.query_rewriter(state)
                if not state_after_rewrite.get("generated_queries"):
                    print(f"   âŒ ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨")
                    results.append({
                        "question_num": idx,
                        "question": question,
                        "queries": "",
                        "similarity": 0.0
                    })
                    continue

                # ìƒíƒœ ì—…ë°ì´íŠ¸
                state = web_agent_state(
                    user_question=question,
                    generated_queries=state_after_rewrite["generated_queries"],
                    collected_documents=[],
                    filtered_documents=[],
                    similarity_score=0.0,
                    final_answer="",
                    answer_type="",
                    search_results=[]
                )

                # 2. document_collector ì‹¤í–‰
                state_after_collect = await web_agent.document_collector(state)
                if not state_after_collect.get("collected_documents"):
                    print(f"   âŒ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨")
                    results.append({
                        "question_num": idx,
                        "question": question,
                        "queries": ", ".join(state_after_rewrite["generated_queries"]),
                        "similarity": 0.0
                    })
                    continue

                # ìƒíƒœ ì—…ë°ì´íŠ¸
                state = web_agent_state(
                    user_question=question,
                    generated_queries=state_after_rewrite["generated_queries"],
                    collected_documents=state_after_collect["collected_documents"],
                    filtered_documents=[],
                    similarity_score=0.0,
                    final_answer="",
                    answer_type="",
                    search_results=[]
                )

                # 3. document_filter ì‹¤í–‰ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
                state_after_filter = await web_agent.document_filter(state)
                similarity_score = state_after_filter.get("similarity_score", 0.0)

                queries_str = ", ".join(state_after_rewrite["generated_queries"])

                print(f"   âœ… ì™„ë£Œ - ì¿¼ë¦¬: {len(state_after_rewrite['generated_queries'])}ê°œ, ìœ ì‚¬ë„: {similarity_score:.4f}")

                # ê²°ê³¼ ì €ì¥
                results.append({
                    "question_num": idx,
                    "question": question,
                    "queries": queries_str,
                    "similarity": similarity_score
                })

                # ì½˜ì†” ì¶œë ¥
                print(f"   ğŸ“ ì§ˆë¬¸: {question}")
                print(f"   ğŸ” ìƒì„±ëœ ì¿¼ë¦¬: {queries_str}")
                print(f"   ğŸ“Š í‰ê·  ìœ ì‚¬ë„: {similarity_score:.4f}")

            except Exception as e:
                print(f"   âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                results.append({
                    "question_num": idx,
                    "question": question,
                    "queries": "",
                    "similarity": 0.0
                })

        # ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ í›„ ì§§ì€ ëŒ€ê¸° (ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
        if batch_end < total_questions:
            wait_time = 5  # 30ì´ˆì—ì„œ 5ì´ˆë¡œ ë‹¨ì¶• (ì¬ì‹œë„ ë¡œì§ì´ ìˆìœ¼ë‹ˆ ë” ê³µê²©ì ìœ¼ë¡œ)
            print(f"\nâ³ ë°°ì¹˜ {batch_num} ì™„ë£Œ. ë‹¤ìŒ ë°°ì¹˜ ì¤€ë¹„ì„ ìœ„í•´ {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘...")
            await asyncio.sleep(wait_time)
            print("âœ… ëŒ€ê¸° ì™„ë£Œ. ë‹¤ìŒ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # CSV íŒŒì¼ ì €ì¥
    save_results_to_csv(results, selected_llm)

    print(f"\n=== ì •ëŸ‰ í‰ê°€ ì™„ë£Œ ===")
    print(f"ì²˜ë¦¬ëœ ì§ˆë¬¸ ìˆ˜: {len(results)}")
    if results:
        avg_similarity = sum(r["similarity"] for r in results) / len(results)
        print(f"ì „ì²´ í‰ê·  ìœ ì‚¬ë„: {avg_similarity:.4f}")


def save_results_to_csv(results, model_name):
    """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{model_name}_result_{timestamp}.csv"

    try:
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['ì§ˆë¬¸ë²ˆí˜¸', 'ì§ˆë¬¸ë‚´ìš©', 'ìƒì„±ëœì¿¼ë¦¬', 'í‰ê· ìœ ì‚¬ë„']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

            writer.writeheader()
            for result in results:
                writer.writerow({
                    'ì§ˆë¬¸ë²ˆí˜¸': result['question_num'],
                    'ì§ˆë¬¸ë‚´ìš©': result['question'],
                    'ìƒì„±ëœì¿¼ë¦¬': result['queries'],
                    'í‰ê· ìœ ì‚¬ë„': result['similarity']
                })

        print(f"âœ… ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")


async def main():
    """ë©”ì¸ í•¨ìˆ˜ - LLM ëª¨ë¸ ì„ íƒ ë° ëª¨ë“œ ì„ íƒ"""
    print("=== ì›¹ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ í”„ë¡œê·¸ë¨ ===")

    # 1. LLM ëª¨ë¸ ì„ íƒ
    selected_llm = select_llm_model()
    print(f"ì„ íƒëœ LLM: {selected_llm}")

    # 2. ëª¨ë“œ ì„ íƒ
    selected_mode = select_mode()
    print(f"ì„ íƒëœ ëª¨ë“œ: {selected_mode}")

    # 3. ì„ íƒëœ ëª¨ë“œì— ë”°ë¼ ì‹¤í–‰
    if selected_mode == "search_test":
        # ëª¨ë“œ 1: ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ê¸°ì¡´ ë¡œì§)
        await test_web_agent_interactive(selected_llm)
    elif selected_mode == "quantitative_evaluation":
        # ëª¨ë“œ 2: ì •ëŸ‰ í‰ê°€
        await quantitative_evaluation(selected_llm)


async def test_web_agent_interactive(selected_llm):
    """ì›¹ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¥¼ ëŒ€í™”í˜•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜ (ê¸°ì¡´ test_web_agent)"""
    print("\n=== ì›¹ ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ===")
    print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ì…ë ¥):")

    # ì›¹ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    try:
        web_agent = web_agent_workflow(llm_type=selected_llm, web_search_tool_class=WebSearchTool)
        print("âœ… ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì„±ê³µ")
    except Exception as e:
        print(f"âŒ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    while True:
        try:
            # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
            question = input("\nì§ˆë¬¸: ").strip()

            # ì¢…ë£Œ ì¡°ê±´
            if question.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                print("í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            if not question:
                print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue

            print(f"\nê²€ìƒ‰ ì¤‘... ì§ˆë¬¸: {question}")
            print("=" * 60)

            # ì›¹ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            result = await web_agent.run(question)

            # ê²°ê³¼ ì¶œë ¥
            print("\n" + "=" * 60)
            print("ğŸ” ê²€ìƒ‰ ê²°ê³¼")
            print("=" * 60)

            if result["success"]:
                print(f"âœ… ê²€ìƒ‰ ì„±ê³µ!")
                print(f"ğŸ“Š ìƒìœ„ 4ê°œ ë¬¸ì„œì˜ í‰ê·  ìœ ì‚¬ë„: {result.get('similarity_score', 0):.4f}")
                print(f"ğŸ“„ ì‚¬ìš©ëœ ë¬¸ì„œ ìˆ˜: {len(result.get('search_results', []))}")
                print(f"ğŸ¯ ë‹µë³€ ë°©ì‹: {result.get('answer_type', 'N/A')}")
                print(f"âš–ï¸ ìœ ì‚¬ë„ ì„ê³„ì¹˜: {result.get('similarity_threshold', 0.48)}")

                # ìœ ì‚¬ë„ì— ë”°ë¥¸ ë‹µë³€ ëª¨ë“œ í‘œì‹œ
                if result.get('similarity_score', 0) >= result.get('similarity_threshold', 0.48):
                    print("ğŸ”¥ ê³ ìœ ì‚¬ë„ ëª¨ë“œ: í†µí•© ë¶„ì„ ë‹µë³€")
                else:
                    print("ğŸ“„ ì €ìœ ì‚¬ë„ ëª¨ë“œ: ë¬¸ì„œë³„ ìš”ì•½")

                print("\nğŸ’¬ ë‹µë³€ ë‚´ìš©:")
                print("-" * 40)
                print(result["answer"])
                print("-" * 40)

            else:
                print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {result['answer']}")

        except KeyboardInterrupt:
            print("\n\ní”„ë¡œê·¸ë¨ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
    asyncio.run(main())